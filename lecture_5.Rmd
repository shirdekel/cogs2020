---
title: "Lecture 5 - Central limit theorem"
author: "Author: Matthew J. Cossley"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float:
        collapsed: false
        smooth_scroll: true
    toc_depth: 2
    fig_caption: yes
    # code_folding: show
    number_sections: false
    theme: cosmo
fontsize: 14pt
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Learning objectives
* ...
* ...

## Central limit theorem

The **central limit theorem** tells us that the sum of
independent and identically distributed random variables
approximates a Normal distribution.

Let 

$\boldsymbol{Y} = \boldsymbol{X}_1 + \boldsymbol{X}_2 + \dots + \boldsymbol{X}_n$

and 

$\boldsymbol{X}_i \sim \boldsymbol{D}$

where $\boldsymbol{D}$ can have any distribution whatsoever.
Then,

$\boldsymbol{Y} \sim N(\mu_{Y}, \sigma_{y}^2)$

where $N$ stands for a *Normal* distribution.

It turns out that we can show:

$\mu_{Y} = \mu_{X}$ 

$\sigma_{y}^2 = \frac{\sigma_{X}^2}{n}$

As a matter of terminology, $\frac{\sigma_{X}^2}{\sqrt{n}}$
is called the *standard error*.