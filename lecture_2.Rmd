---
title: "Lecture 2 - Descriptive statistics"
author: "Author: Matthew J. Cossley"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float:
        collapsed: true
        smooth_scroll: true
    toc_depth: 3
    fig_caption: yes
    # code_folding: show
    number_sections: false
    theme: cosmo
fontsize: 14pt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Learning objectives

- Understand conceptually and be able to compute by hand and using R the
  following descriptive statistics:
  - sample mean
  - sample median
  - sample mode
  - sample variance
  - sample standard deviation
  - sample range

- Understand and be able to generate using R histograms and dot plots using
  ggplot.

- Understand and be able to add line segment annotations to ggplot plots.

- Understand and be able to control aspect ratio and axis text font size of
  ggplot figures.

## What is statistics?

Very roughly speaking, we can think of statistics as a
mathematical tool for describing data using **descriptive
statistics** and for making decisions on the basis of data
using **inferential statistics**. In statistics, it is safe
to think of all data as coming from an experiment. The act
of performing an experiment is equivalent to simply
assigning numbers to events that we observed in the world.
These numbers are called a **sample**. In general, if we
perform an experiment in which we observe $n$ outcomes, then
our sample is written as:

$$
\boldsymbol{x} = ( x_1, x_2, x_3, ..., x_n )
$$

For example, we might perform an experiment where we observe
a rat navigate a maze several times, and measure the time to
completion for each maze run. Suppose that we observed 10
runs with the following times in seconds:

$$
\boldsymbol{x} = ( 52.38, 55.41, 70.88, 43.30, 50.15, 41.99, 36.82, 34.05, 52.70, 72.25 )
$$

We would say that $\boldsymbol{x}$ is our sample. If
somebody asks you about your experiment, it is often not
very practical to list all the numbers that you observed.
Instead, you would want some way to concisely summarise the
sample that you obtained. In the following sections, we will
cover some basic **descriptive statistics** that do exactly
this.

In general, we may not want to merely describe our data, but
we may want to use it to help us make decisions. For
example, suppose that any rat that can reliably run this
maze in under 50 seconds is considered a super-mega-genius.
Should you put in the super-mega-genius paperwork for this
rat? Later in the course, we will go deeper into the
**inferential statistics** that will help us in this
scenario, but we will begin developing an intuition now.

As it turns out, answering this question intelligently
requires using our **sample** to make inferences about a
**population**, which can be roughly thought of as the set
of all possible maze times and their relative frequencies
that you will ever observe you run this experiment forever.

Another way of thinking about it is that the **population**
is the process that generates the maze times you will
observe whenever you perform your experiment.

A **population** is the true state of the world... it is
either the entire collection of things that you are
interested in studying, or else it is the process that
generates a potentially infinite set of things that you are
interested in.

For example, if you perform your experiment another two
times, you might end up with the following samples:

$$
\boldsymbol{x_1} = ( 52.38, 55.41, 70.88, 43.30, 50.15, 41.99, 36.82, 34.05, 52.70, 72.25 )
$$
$$
\boldsymbol{x_2} = ( 62.36, 53.89, 53.95, 33.81, 61.12, 61.48, 36.89, 49.45, 52.50, 50.95 )
$$
$$
\boldsymbol{x_3} = ( 52.04, 48.28, 48.12, 58.89, 51.76, 42.88, 49.04, 60.41, 53.99, 70.06 )
$$

Each sample is composed of very similar but not identical
observations. In statistics, we think of each **sample** as
being drawn or generated from a **population**, and we want
to estimate properties of the **population** by using our
**sample**.

To review, we will want to concisely describe our data using
**descriptive statistics**, and we will want to use our data
to make decisions using **inferential statistics**.

## Describing data

### Central tendency of a sample

Given a sample, a measure of central tendency is supposed to
tell us where most values tend to be clustered. One very
common measure of sample central tendency is called the
**sample mean**. The **sample mean** is denoted by
$\overline{\boldsymbol{x}}$, and is defined by the following
equation:

$$
\overline{\boldsymbol{x}} = \frac{x_1 + x_2 + x_3 + ... + x_n}{n}
$$

We can write this concisely as:

$$
\overline{\boldsymbol{x}} = \frac{1}{n} \sum_{i=1}^{n} x_{i}
$$

Another common measure of sample central tendency is called
the **sample median**. We will denote it by
$\widetilde{\boldsymbol{x}}$, and it is defined simply as
the value that splits the observations in half. Finally,
**sample mode** is the element that occurs most often in the
sample.

### Central tendency by hand

Suppose you have the following observations:
$$
\boldsymbol{x} = (55, 35, 23, 44, 31)
$$

To compute the mean, we simply plug these numbers into the
equation.
$$
\overline{\boldsymbol{x}} = \frac{55 + 35 + 23 + 44 + 31}{5} = \frac{188}{5} = 37.6
$$

To compute the median, first sort the data from smallest to
largest:
$$
\boldsymbol{x}_{sorted} = (23, 31, 35, 44, 55)
$$

Then, pick the value that ends up in the middle:
$$
\widetilde{\boldsymbol{x}} = 35
$$

Since we have an odd number of observations, finding the
median is pretty intuitive, but what if we had an even
number of observations? In this case, we will take the mean
of the middle two numbers.

$$
\boldsymbol{x} = (55, 35, 23, 44)
$$

$$
\boldsymbol{x}_{sorted} = (23, 35, 44, 55)
$$

$$
\widetilde{\boldsymbol{x}} = \frac{35 + 44}{2} = 39.5
$$


### Central tendency using R

In general, things are easier and we are happier and more
productive human beings if we use R. Our first action will
almost always be to start R and load the `data.table` and
`ggplot2` libraries.

```{r eval=TRUE, message=FALSE}
library(data.table)
library(ggplot2)
rm(list=ls())
```

It is also good practice to clear everything from the
current session memory at the top of the script.

```{r eval=TRUE, message=FALSE}
rm(list=ls())
```

Next, we just store our sample observations in a variable
`x`, and use R's built-in functions `mean()` and `median()`
to compute the sample mean and sample median.

```{r eval=TRUE, message=FALSE}
x <- c(55, 35, 23, 44, 31)
mean(x)
median(x)
```

While we're here, we might as well verify our computations
for both samples.

```{r eval=TRUE, message=FALSE}
x <- c(55, 35, 23, 44)
mean(x)
median(x)
```

### Central tendency and outliers

Sometimes a sample contains a few observations that are very
different from the majority of the others. Theses
observations are called **outliers**. How will outliers
influence our measures of central tendency? To answer this
question, consider the following example:

To study the possible effects of a new noise pollution
ordinance, 18 power lawn mowers were observed and their
noise levels were recorded to the nearest decibel. The
following data were obtained:

```{r eval=TRUE, message=FALSE}
noise_levels <-
    c(95,120,117,99,110,107,125,98,85,127,105,114,103,112,92,101,122,120)
mower_id <- 1:length(noise_levels)

d <- data.table(mower_id, noise_levels)
```

Here, we entered our observations into the variable
`noise_levels`, created a variable called `mower_id` to
indicate which power lawn mower our measurement was taken
from, and finally created a `data.table` with each of these
two variables as columns.

Taking a look at our sample, no observation seems much
different from any other (i.e., there are no outliers). Lets
make a plot to really persuade ourselves that this is true.

```{r eval=TRUE, message=FALSE}
ggplot(d, aes(x=noise_levels)) +
    geom_dotplot() +
    theme(aspect.ratio = 1) +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```

Here, we have plotted our data as a dot plot, and indeed,
there do not appear to be any major outliers. How do the
sample mean and sample median behave in this case?

```{r eval=TRUE, message=FALSE}
noise_mean <- d[, mean(noise_levels)]
noise_median <- d[, median(noise_levels)]

print(c(noise_mean, noise_median))
```

The sample mean and sample median are nearly identical when
there are no outliers. For practice, lets add the mean and
median to the plot.

```{r eval=TRUE, message=FALSE}
ggplot(d, aes(x=noise_levels)) +
  geom_dotplot() +
  theme(aspect.ratio = 1) +
  geom_vline(xintercept = noise_mean, colour = 'red') +
    geom_vline(xintercept = noise_median, colour = 'blue') +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```

Lets consider another example to see how the sample mean and
sample median behave when our sample does contain outliers.

Waiting to cross a busy street on the way to class one
morning, Professor J. noted the following times in seconds
between cars traveling in the same direction:

```{r eval=TRUE, message=FALSE}
times <- c(6,3,5,6,4,3,5,4,6,3,4,5,4,18)
times_id <- 1:length(times)

d <- data.table(times_id, times)

ggplot(d, aes(x=times)) +
  geom_dotplot() +
    theme(aspect.ratio = 1) +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```

Here, we have followed the same procedure that we followed
in our previous example, ultimately getting a `data.table`
representation of our sample, and plotting it as a dot plot.

The dotplot reveals that the times are closely grouped
around 4 or 5, except for one outlier that is much larger
than the rest. How do the sample mean and sample median
behave in this scenario?

```{r eval=TRUE, message=FALSE}
noise_mean <- d[, mean(times)]
noise_median <- d[, median(times)]
ggplot(d, aes(x=times)) +
  geom_dotplot() +
  theme(aspect.ratio = 1) +
  geom_vline(xintercept = noise_mean, colour = 'red') +
    geom_vline(xintercept = noise_median, colour = 'blue') +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```

Here, you can see that the mean, but much less so the
median, is sensitive to outliers.

So, which is a better measure of central tendency? The
answer to this question depends entirely on what you think
is an outlier and how much you care about them. Saying much
more than that is beyond the scope of this lecture, but we
should leave with at least a simple lesson: **it is always a
good idea to identify and investigate outliers in our
data.**

In this silly example, lets say that Prof J. noticed the
outlier, investigated it, and discovered that there was a
stop light a block away that had turned red. Mystery solved.

### Practice central tendency

Compute the mean and the median of each sample described
above for the rat maze navigation data that we opened the
lecture notes with:

$$
\boldsymbol{x_1} = ( 52.38, 55.41, 70.88, 43.30, 50.15, 41.99, 36.82, 34.05, 52.70, 72.25 )
$$

$$
\boldsymbol{x_2} = ( 62.36, 53.89, 53.95, 33.81, 61.12, 61.48, 36.89, 49.45, 52.50, 50.95 )
$$

$$
\boldsymbol{x_3} = ( 52.04, 48.28, 48.12, 58.89, 51.76, 42.88, 49.04, 60.41, 53.99, 70.06 )
$$


### Visualising samples with histograms

In our previous examples, we have used dot plots to show how
our sample data is distributed. A more common approach -- at
least in cognitive science -- is to use histograms for this
purpose. We will dive into this in the following example.

One of the major indicators of air pollution in large cities
and industrial belts is the concentration of ozone in the
atmosphere. From massive data collected by LA County
authorities, 78 measurements of ozone concentration in the
downtown LA area during the summer of 1966 and 1967 are
recorded in the table below. Each measurement is an average
of hourly readings taken every fourth day.

```{r eval=TRUE, message=FALSE}
ozone <- c( 3.5, 1.4, 6.6, 6.0, 4.2, 4.4, 5.3, 5.6, 6.8, 2.5, 5.4, 4.4, 5.4,
  4.7, 3.5, 4.0, 2.4, 3.0, 5.6, 4.7, 6.5, 3.0, 4.1, 3.4, 6.8, 1.7, 5.3, 4.7,
  7.4, 6.0, 6.7, 11.7, 5.5, 1.1, 5.1, 5.6, 5.5, 1.4, 3.9, 6.6, 6.2, 7.5, 6.2,
  6.0, 5.8, 2.8, 6.1, 4.1, 5.7, 5.8, 3.1, 5.8, 1.6, 2.5, 8.1, 6.6, 6.8, 3.1,
  4.7, 3.8, 5.9, 3.3, 6.2, 7.6, 6.6, 4.4, 5.7, 4.5, 3.7, 9.4 )

ozone_id <- 1:length(ozone)

d <- data.table(ozone, ozone_id)
```

Here, we have followed the same procedure we ran through in
the previous examples. Lets begin by simply plotting a
histogram representation of this sample.

```{r eval=TRUE, message=FALSE}
ggplot(d, aes(x=ozone)) +
  geom_histogram(col='black', fill='white') +
    scale_y_continuous('count', 1:10) +
    theme(aspect.ratio = 1) +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```

Dot plots and histograms convey very much the same
information. A good way to see this is to plot them both at
the same time.

```{r eval=TRUE, message=FALSE}
ggplot(d, aes(x=ozone)) +
  geom_histogram(col='black', fill='white') +
  geom_dotplot() +
  scale_y_continuous('count', 1:10) +
    theme(aspect.ratio = 1) +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```

Working with histograms can involve a bit of tweaking to get
things to look nice. For example, you can control how big or
small the bins are using the `breaks` argument

<div class = "row">  
<div class = "col-md-6">
```{r eval=TRUE, message=FALSE, fig.width = 4}
## big bins
b <- seq(0,12,by=2.0)
ggplot(d, aes(x=ozone)) +
    geom_histogram(
        breaks=b,
        col='black',
        fill='white') +
    theme(aspect.ratio = 1) +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```
</div>  
<div class = "col-md-6">
```{r eval=TRUE, message=FALSE, fig.width = 4}
## small bins
b <- seq(0,12,by=0.25)
ggplot(d, aes(x=ozone)) +
    geom_histogram(
        breaks=b,
        col='black',
        fill='white') +
    theme(aspect.ratio = 1) +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```
</div>
</div>

`geom_density()` can be a nice addition to histograms.
However, a problem is that `geom_density()` normalises the
total area to 1, but a regular old histogram, by default,
doesn't. We can force normalisation by using
`geom_histogram(aes(y=..density..))`.

<div class = "row">  
<div class = "col-md-6">
```{r eval=TRUE, message=FALSE, fig.width = 4}
## without aes(y=..density..)
b <- seq(0,12,by=0.25)
ggplot(d, aes(x=ozone)) +
    geom_histogram(
        aes(),
        breaks=b,
        col='black',
        fill='white') +
  geom_density(colour='red') +
    theme(aspect.ratio = 1) +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```
</div>
<div class = "col-md-6">
```{r eval=TRUE, message=FALSE, fig.width = 4}
## with aes(y=..density..)
b <- seq(0,12,by=0.25)
ggplot(d, aes(x=ozone)) +
  geom_histogram(
    aes(y=..density..),
    breaks=b,
    col='black',
    fill='white') +
  geom_density(colour='red') +
    theme(aspect.ratio = 1) +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```
</div>
</div>

Next, lets add vertical lines to show the sample mean and
sample median to the histogram using small bins. Lets also
do the same thing using large bins so we can see that the
selection of bin size is influencing the aesthetics of our
plot, but is not changing the fundamental information in our
plot.

<div class = "row">  
<div class = "col-md-6">
```{r eval=TRUE, message=FALSE, fig.width = 4}
## small bins
b <- seq(0,12,by=0.25)
ggplot(d, aes(x=ozone)) +
  geom_histogram(
    aes(y=..density..),
    breaks=b,
    col='black',
    fill='white') +
  geom_density(colour='black', size=1.25) +
  theme(aspect.ratio = 1) +
  geom_vline(xintercept = d[, mean(ozone)], colour='red') +
    geom_vline(xintercept = d[, median(ozone)], colour='blue') +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```
</div>
<div class = "col-md-6">
```{r eval=TRUE, message=FALSE, fig.width = 4}
## slightly larger bins
b <- seq(0,12,by=1.0)
ggplot(d, aes(x=ozone)) +
  geom_histogram(
    aes(y=..density..),
    breaks=b,
    col='black',
    fill='white') +
  geom_density(colour='black', size=1.25) +
  theme(aspect.ratio = 1) +
  geom_vline(xintercept = d[, mean(ozone)], colour='red') +
    geom_vline(xintercept = d[, median(ozone)], colour='blue') +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```
</div>
</div>

### Spread of a sample

Measures of spread of a sample are supposed to tell us how
widely the sample observations are distributed. One very
common measure of spread is called **sample variance**. It
is denoted by $\boldsymbol{s}^2$ and it is defined as:

$$
\boldsymbol{s}^2 = \frac{1}{n-1} \sum_{i=1}^{n} ( x_{i} - \overline{\boldsymbol{x}} )^2
$$

Consider the following sample:

$$
\boldsymbol{x} = (55, 35, 23, 44)
$$

If for some reason you needed to compute sample variance,
and every computer near you was broken, then you could
compute the sample variance of this sample by hand as
follows:

$$
\boldsymbol{s}^2 = \frac{ (55-39.25)^2 + (35 -39.25)^2 + (23-39.25)^2 + (44-39.25)^2 }{4-1}
$$

$$
\boldsymbol{s}^2 = \frac{ (15.75)^2 + (-4.25)^2 + (-16.25)^2 + (4.75)^2 }{4-1}
$$

$$
\boldsymbol{s}^2 = \frac{ 248.0625 + 18.0625 + 264.0625 + 22.5625 }{4-1}
$$

$$
\boldsymbol{s}^2 = \frac{ 552.75 }{4-1} = 184.25
$$

Well, that sucked, and in a moment we will see that R will
do this for us with grace and ease. Before we celebrate the
awesomeness of R, lets cover two more measures of spread.

One additional measure is called the **sample standard
deviation**. It is denoted by, $\boldsymbol{s}$, and it is
defined simply as the square root of the sample variance.

$$
\boldsymbol{s} = \sqrt{\boldsymbol{s}^2}
$$

The third measure of spread that we will consider is called
the **sample range**, and it is defined as the difference
between the most extreme observed values

Okay, now lets use R to quickly compute the all measures of
central tendency and spread that we have learned about so
far.

```{r eval=TRUE, message=FALSE}

ozone_mean   <- d[, mean(ozone)]
ozone_median <- d[, median(ozone)]
ozone_var    <- d[, var(ozone)]
ozone_sd     <- d[, sd(ozone)]
ozone_range  <- d[, range(ozone)]
ozone_range  <- diff(ozone_range)

print(ozone_var)
print(ozone_sd)
print(ozone_range)

```

We will now finish up by adding the sample mean, sample
variance, standard deviation, and range to our previous
histogram plot.

```{r eval=TRUE, message=FALSE}
b <- seq(0,12,by=1.0)
ggplot(d, aes(x=ozone)) +
  geom_histogram(aes(y=..density..), breaks=b, col='black', fill='white') +
  geom_density(colour='black', size=1.25) +
  theme(aspect.ratio = 1) +
  geom_vline(xintercept = ozone_mean, colour='black') +
  geom_segment(
    aes(x=ozone_mean-ozone_var, xend=ozone_mean+ozone_var, y=.3, yend=.3),
    colour='red') +
  geom_segment(
    aes(x=ozone_mean-ozone_sd, xend=ozone_mean+ozone_sd, y=.35, yend=.35),
    colour='blue') +
  geom_segment(
    aes(x=ozone_mean-ozone_range, xend=ozone_mean+ozone_range, y=.4, yend=.4),
    colour='green') +
    theme(
        aspect.ratio=1,
        axis.title=element_text(size=14),
        axis.text=element_text(size=12)
    )
```

### Practice it all 

Compute the mean, median, and all three measures of sample
spread for each sample described above for the rat maze
navigation data that we opened the lecture notes with:

$$
\boldsymbol{x_1} = ( 52.38, 55.41, 70.88, 43.30, 50.15, 41.99, 36.82, 34.05, 52.70, 72.25 )
$$

$$
\boldsymbol{x_2} = ( 62.36, 53.89, 53.95, 33.81, 61.12, 61.48, 36.89, 49.45, 52.50, 50.95 )
$$

$$
\boldsymbol{x_3} = ( 52.04, 48.28, 48.12, 58.89, 51.76, 42.88, 49.04, 60.41, 53.99, 70.06 )
$$

To do this, first use `c()` to concatenate all three samples
into one mega-sample.

Make a histogram of the final concatenated result and add
lines to visualise the mean, median, and different measures
of spread.