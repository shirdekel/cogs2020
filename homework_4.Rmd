---
title: "Homework 4"
author: "Author: Matthew J. Cossley"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float:
        collapsed: true
        smooth_scroll: true
    toc_depth: 3
    fig_caption: yes
    number_sections: false
    theme: cosmo
fontsize: 14pt
---

<div style="color:#990000">
**Note that this homework is not yet finalised. I am posting
it here for practice purposes only.**
<br></br>
</div>

<style type="text/css">
.table {
    width: 40%;
***
</style>


```{r, echo=F}
library(data.table)
library(ggplot2)
library(ggpubr)
```

## General instructions
When responding to every question that requires you to
perform a hypothesis test, please follow the instructions
laid out below.

<b>1\. Specify the null and alternative hypotheses ($H_0$ and
   $H_1$) in terms of a distribution and population
   parameter $\theta$.</b>

You will need to perform this step in order to correctly
perform any hypothesis test, but for the homework, just
writing it in comments is adequate (your comments won't be
graded). E.g., if asked to test the hypothesis that the true
mean of a random variable is greater than 0.5, you might
write:

```{r, eval=F}
# In this problem, the parameter theta that we are
# interested in is the population mean mu

# H0: mu = 0.5
# H1: mu > 0.5
```

<b>2\. Specify the type I error rate -- denoted by the symbol
   $\alpha$ -- you are willing to tolerate.</b>

For every problem in this homework use $\alpha=0.05$. Again,
writing this in comments is adequate (your comments won't be
graded). E.g., you could write:

```{r, eval=F}
# set type I error rate
# alpha = 0.05
```
   
<b>3\. Specify the sample statistic that you will use to
   estimate the population parameter in step 1 and state how
   it is distributed under the assumption that $H_0$ is
   true.</b>
   
* A good way to begin is to again write out some comments.
To continue with the example from step 1, you might begin by
writing:

```{r, eval=F}
# theta_hat = mu_hat
# mu_hat = x_bar
# x_bar ~ N(mu_x_bar, sig_x_bar)
# mu_x_bar = mu_x
# sig_x_bar = sig_x

# NOTE: This example assumes sig_x is known.
```

* Create a vector named `theta_hat_x` that contains the possible
outcomes of $\widehat{\theta}$.

   * If $\widehat{\theta}$ is discrete with a finite range
   then `theta_hat_x` must contain all possible outcomes.
   
   * If $\widehat{\theta}$ is continuous with a finite range
   then use `theta_hat_x` must start at the minimum valued
   outcome, end at the maximum valued outcome, and contain
   all the values between these two endpoints in increments
   of `0.01`.
   
   * If $\widehat{\theta}$ is discrete with an infinite
   range then `theta_hat_x` must start 4 standard deviations
   below the the mean, end 3 standard deviations above the
   mean, and must contain all the values between these two
   endpoints in increments of `0.01`.
   
   * If $\widehat{\theta}$ is continuous with an infinite
   range then `theta_hat_x` must start 4 standard deviations
   below the the mean, end 3 standard deviations above the
   mean, and must contain all the values between these two
   endpoints in increments of `0.01`.
   
* Carrying on with the example, you would write:

```{r, eval=F}
# theta_hat = mu_hat
# mu_hat = x_bar

# x_bar is continuous

# NOTE: You will have to think about whether or not x_bar
# has a finite or infinite range for each particular
# scenario. For this exampl, lets assume it is infinite
# range.

theta_hat_x <- seq(-4*sig_x, 4*sigx, 0.01)
```

* Create a variable named `theta_hat_p` and set its value to
the probability mass (if discrete) or probability density
(if continuous) corresponding to each possible outcome of
$\widehat{\theta}$ stored in variable `theta_hat_x`.

```{r, eval=F}
# Since theta_hat = x_bar and x_bar is normal, we use dnorm()
# Assuming that you have previously defined  mu_x_bar and
# sig_x_bar, you could write:
theta_hat_p <- dnorm(theta_hat_x, mu_x_bar, sig_x_bar)
```

* Plot the $\widehat{\theta}$ sampling distribution. Put the
possible outcomes of $\widehat{\theta}$ on the x-axis and
put the probability density or mass (whichever is
appropriate) on the y-axis. Use only `ggplot()` and
`geom_line()` (if continuous) or `geom_point()` (if
discrete). You should use this plot to contextualize the
p-value and critical value computed below (i.e., use it to
check your work!).

```{r, eval=F}
d <- data.table(theta_hat_x, theta_hat_p)
ggplot(d, aes(theta_hat_x, theta_hat_p)) +
   geom_line()  
   # geom_line() because in this example theta_har is x_bar is continuous
```

   
<b>4\. Obtain a random sample and use it to compute the
   sample statistic from step 3. Call this value
   $\widehat{\theta}_{\text{obs}}$</b>

* Create a variable named `theta_hat_obs` and set its value to
$\widehat{\theta}_{\text{obs}}$.

```{r, eval=F}
# Obtaining the observed value will be matter of wrangling a
# data.table or maybe simply reading the problem carefully.
# In this example, look something like:
x_bar_obs <- dt[, mean(x)]
theta_hat_obs <- x_bar_obs
```

<b>5\. If $\widehat{\theta}_{\text{obs}}$ is very unlikely to
   occur under the assumption that $H_0$ is true, then
   reject $H_0$. Otherwise, do not reject $H_0$.</b>

* Create a variable named `p_val` and set its value to
$P(\widehat{\theta}_{\text{obs}} | H_0)$.

```{r, eval=F}
# In this example, p_hat_obs is x_bar_obs which comes from a
# Normal so we use pnorm() with lower.tail determined by the
# alternative hypothesis.
p_val <- pnorm(x_bar_obs, mu_x_bar, sig_x_bar, lower.tail=FALSE)
```

* Create a value named `decision` and set its value either to
`reject H0` or `fail to reject H0`.

```{r, eval=F}
# Lets assume p_val < 0.05. 
# Then we would write:
decision <- 'reject H0'
```

* If performing a one-tailed test, create a variable named
`theta_hat_crit` and set its value to the critical value. If
performing a 2-tailed test, create two variables,
`theta_hat_crit_lower` and `theta_hat_crit_upper` and set
their values to the corresponding critical values.

```{r, eval=F}
# Our running example is a one-tailed test so we only have
# one critical value. Furthermore, x_bar is normal so we use
# the qnorm() function to get the x_bar outcome that
# corresponds to P(X > x | H0) < 0.05.
theta_hat_crit <- qnorm(0.05, mu_x_bar, sig_x_bar, lower.tail=FALSE)
```

* Calculate the 95% confidence interval estimate of the
parameter in step 1. Create a variable named `ci_lower` and
set its value to the lower bound of this confidence
interval, and create a variable named `ci_upper` and set its
value to the upper bound of this confidence interval. Make
sure that the decision you reach on the basis of this
confidence interval is the same as you reached using the
p-value.

```{r, eval=F}
# The width of the confidence interval is easy to obtain if
# you remember that it is the same as the width between the
# two critical values if your test was a two-tailed test.
x_bar_crit_lower <- qnorm(0.025, mu_x_bar, sig_x_bar, lower.tail=TRUE)
x_bar_crit_upper <- qnorm(0.025, mu_x_bar, sig_x_bar, lower.tail=FALSE)
x_bar_ci_width <- x_bar_crit_upper - x_bar_crit_lower

# The centre of the confidence interval is just the
# theta_hat_obs, which in this case is x_bar_obs.
x_bar_ci_lower <- x_bar_obs - x_bar_xi_width / 2
x_bar_ci_upper <- x_bar_obs + x_bar_xi_width / 2
```


<b>6\. If there is a built-in R function that will perform the
test in question, use and verify that it returns the same
results as running through steps 1 through 5 in long form.</b>

* Create a variable named `r_result` and set its value to
the result of the built-in R function. If no built-in
function exists, set `r_result <- "does not exist"`.

```{r, eval=F}
# In our running example we know sig_x, and so we are
# performing a Normal test. There is no built-in R function
# to perform this test.
r_result <- "does not exist"

# If you did not know sig_x, and you were consequently
# performing a t-test, then you would use code similar to:
x <- dt[, x]
r_result <- t.test(x, mu=0.5, alternative='greater')
```

<b>7\. Create problem-specific variables to store the work form
the previous steps to facilitate grading.</b>

* For a one-tailed test use:
```{r, eval=F}
prob_x_theta_hat_x <- theta_hat_x
prob_x_theta_hat_p <- theta_hat_p
prob_x_theta_hat_obs <- theta_hat_obs
prob_x_pval <- pval
prob_x_theta_hat_crit <- theta_hat_crit
prob_x_ci_lower <- ci_lower
prob_x_ci_upper <- ci_upper
prob_x_decision <- decision
prob_x_r_result <- r_result
```

* For a two-tailed test use:
```{r, eval=F}
prob_x_theta_hat_x <- theta_hat_x
prob_x_theta_hat_p <- theta_hat_p
prob_x_theta_hat_obs <- theta_hat_obs
prob_x_pval_lower <- pval_lower
prob_x_pval_upper <- pval_upper
prob_x_theta_hat_crit_lower <- theta_hat_crit_lower
prob_x_theta_hat_crit_upper <- theta_hat_crit_upper
prob_x_ci_lower <- ci_lower
prob_x_ci_upper <- ci_upper
prob_x_decision <- decision
prob_x_r_result <- r_result
```

* Be sure to replace the `x` in the `prob_x` above with the
problem number.

* Also note that I haven't shown how to compute confidence
interval estimates from Binomial random variables (or any
discrete random variable for that matter). It follows the
same principles in most ways as our approach for continuous
random variables, but it turns out to be a bit more
involved. Because of that, I will not ask you to compute CI
estimates of a parameter from a discrete distribution.
Hence, when performing a hypothesis test from a discrete
random variable, use the following:

```{r, eval=F}
prob_x_ci_lower <- NULL
prob_x_ci_upper <- NULL
```

## Problem 0

* Load `data.table` and `ggplot2` but no other packages.

* Do not call `install.packages` anywhere in this script.
Once you installed them once, there is no need to install
them again. If you need to install some other package in the
future, do so by using `install.packages` function in the
console.

* Make sure you are starting with a clean environment by
running `rm(list=ls())`. Running this line of code will
erase any variable defined before it. Do not put this line
of code after anything important to keep for grading.

* Create a variable named `my_name` and set its value equal
to a **character** vector (i.e., letters surrounded by `""`)
containing your name.

* Create a variable named `my_student_id` and set its value
equal to a **character** vector (i.e., letters surrounded by
`""`) containing your student id.

## Problem 1

**(a)** load the data located in the csv file linked below
into a data.table named `d`.

https://crossley.github.io/cogs2020/data/nhp_cat_learn/ii_gabor.csv

This data file contains the results from a monkey performing
a category learning experiment similar to those that we have
seen a handful of times already in this class. On each trial
of the experiment the monkey sees a sine-wave grating and
must learn through trial and error whether that grating is a
member of category A or category B.

**(b)** Change the column names to the following

`col_names <- c('cat', 'x', 'y', 'resp', 'rt', 'phase')`

**(c)** Add a column named `trial` to the data.table that
indicates the trial of the experiment. Note that `trial`
should start at 1 and increment by 1 all the way to the
number of total rows in `d`.

**(d)** Add a column named `block` to the `data.table` that
indicates the block of the experiment, assuming a block size
of 100 trials per block. Note that a block size of 100 does
not divide evenly into the number of rows in `d` (i.e.,
8196), so you will have to be careful and clever in dealing
with this. However you deal with it, the final 96 trials in
`d` should correspond to a block value of 82.

**(e)** Add a column named `acc` to the `data.table` that
indicates whether the response on each trial was correct or
incorrect (e.g., `cat == resp`).

**(f)** Create a new data.table named `dd` that contains
columns for the mean accuracy per block (name this column
`acc_mean`) and the SEM (name this column `acc_err`) per
`block`, grouped by each unique combination of `block` and
`phase`. Please ensure that `dd` contains only `acc_mean`,
`acc_sem`, `block`, and `phase` columns.

**(g)** Plot the mean accuracy per block (`block` on the
x-axis, `acc_mean` on the y-axis). Include error bars at
each data point that represent SEM. Plot phase 1 and phase 2
in different colours.

## Problem 2 - 4
In the dataset from Problem 1, each trial is a Bernoulli
trial with probability of success $p$. This means that
trials are distributed $X \sim Bernoulli(p)$. This also
means that blocks of trials are distributed $X \sim
Binomial(n,p)$, where $n$ is the block size (i.e., number of
trials per block).

**Problem 2.** Test the hypothesis that, for the first 100
trials of phase 1, the monkey is doing no better and no
worse than guessing (i.e., $p = .5$).

**Problem 3.** Test the hypothesis that, for the last 100
trials of phase 1, the monkey is doing better than guessing
(i.e., $p = .5$).

**Problem 4.** Test the hypothesis that, for the first 100
trials of phase 2, the monkey is doing worse than guessing
(i.e., $p = .5$).

## Problem 5-8
Above, we viewed each trial as $Bernoulli(p)$, and each $n$
trials as $Binomial(n,p)$. An alternative framing is to
ignore each individual trial, and instead consider the
random variable

$X = \text{mean accuracy per block}$

In this framing, the experiment results are sampled from
blocks of trials, not from individual trials.

**Problem 5.** Make a deep copy of `d` named `d2`, and then
redefine the block column of `d2` to reflect a block size of
25 trials per block instead of 100. Then, using `d2` as a
base, create a new data.table named `dd2` that contains
columns for the mean accuracy per block (name this column
`acc_mean`) and the SEM (name this column `acc_err`) per
`block`, grouped by each unique combination of `block` and
`phase`. Please ensure that `dd2` contains only `acc_mean`,
`acc_sem`, `block`, and `phase` columns. Repeat the mean
accuracy plot using the new block size to visually check
that your work is doing what you think it's doing (this plot
will not be graded).

**Problem 6.** Test the hypothesis that the mean accuracy in
the first 16 blocks of phase 1 is no greater or worse than
chance (i.e. 50% correct responses).

**Problem 7.** Test the hypothesis that the mean accuracy in
the last 16 blocks of phase 1 is greater than chance.

**Problem 8.**
Test the hypothesis that the mean accuracy in the first 16
blocks of phase 2 less than chance.

## Problem 9
What accounts for the drop in accuracy between phase 1 and
phase 2? To answer this question, investigate the stimuli
the monkey was required to learn between phase 1 and phase
2. Using `ggplot()` and `geom_point()`, make a plot of
stimuli (`x=x, y=y`) coloured by category membership label
(`cat`). Include a separate version of this plot for each
phase in different panels by using `facet_wrap()`. Save the
resulting plot to a variable named `ans_9`.

## problem 10
For the first 16 blocks of phase 1, assume that the true
state of the universe is $\mu=.6$. Given $H_0:\mu=.5$

* compute $\alpha$ and store its value in a variable named `ans_9a`

* compute $\beta$ and store its value in a variable named `ans_9b`

* compute $power$ and store its value in a variable named `ans_9c`

## Problem 11
The number of action potentials generated from a given
neuron in its baseline state when observed for a fixed
period of time is well described by a Poisson distribution.
The Poisson distribution is fully characterised by a single
parameter $\lambda$ called the rate parameter. It turns out
that $\lambda$ is also the mean of the Poisson distribution.
Suppose a group of researchers measured a particular neuron
and observed 5 action potentials in a given time period. Let
$X$ be the Poisson random variable that generated this
result. Test the hypothesis that $\lambda > 4$. You will
need to search the web or use the built-in R help to look
for functions that tell you about Poisson probabilities etc.

## Problem 12

```{r, echo=F, fig.width=10}
n <- 2

mu_x_0 <- 5
sigma_x <- 2 / sqrt(n)
x_crit <- qnorm(0.95, mu_x_0, sigma_x, lower.tail=F)
mu_x_1 <- x_crit

x <- seq(mu_x_0 - 5*sigma_x, mu_x_1 + 5*sigma_x, 0.01)
fx0 <- dnorm(x, mu_x_0, sigma_x)
fx1 <- dnorm(x, mu_x_1, sigma_x)
d <- data.table(x, fx0, fx1)
d[x <= x_crit, region0 := 'I'] # confidence
d[x > x_crit, region0 := 'II'] # alpha
d[x <= x_crit, region1 := 'III'] # beta
d[x > x_crit, region1 := 'IV'] # power

ggplot(d, aes(x=x)) +
  geom_line(aes(y=fx0)) +
  geom_line(aes(y=fx1)) +
  geom_vline(xintercept=x_crit, linetype=2) +
  geom_ribbon(data=d, aes(x=x, ymin=0, ymax=fx0, fill=region0), alpha=0.25) +
  geom_ribbon(data=d, aes(x=x, ymin=0, ymax=fx0, fill=region0), alpha=0.25) +
  geom_ribbon(data=d, aes(x=x, ymin=0, ymax=fx1, fill=region1), alpha=0.25) +
  geom_ribbon(data=d, aes(x=x, ymin=0, ymax=fx1, fill=region1), alpha=0.25) +
  scale_x_continuous(breaks=c(mu_x_1, mu_x_0), labels=c('H1', 'H0')) +
  ylab('Probability Density') +
  theme(legend.title = element_blank())
```

Please respond by assigning `"confidence"`, `"alpha"`,
`"beta"`, or `"power"` to the variables requested below.

* What quantity does region I in the above plot correspond
to? Store your answer in a variable named `ans_12a`.

* What quantity does region II in the above plot correspond
to? Store your answer in a variable named `ans_12b`.

* What quantity does region III in the above plot correspond
to? Store your answer in a variable named `ans_12c`.

* What quantity does region IV in the above plot correspond
to? Store your answer in a variable named `ans_12d`.

* What is the numeric value (to one decimal place) of the
power in this example? Store your answer in a variable named
`ans_12e`.

* Assuming a type I error rate of 0.05, what is the numeric
value (to one decimal place) of confidence of this example?
Store your answer in a variable named `ans_12f`.

* Assuming that the illustrated distributions correspond to
the distribution of sample means, will increasing the sample
size increase the distance between the mean of H1 and H0
distributions? Store your answer using `ans_12g <- "YES"` or
`ans_12g <- "NO"`.

