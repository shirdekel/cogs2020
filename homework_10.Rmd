---
title: "Homework 10"
author: "Author: Matthew J. Cossley"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: true
    toc_float:
        collapsed: false 
        smooth_scroll: true
    toc_depth: 3
    fig_caption: yes
    number_sections: false
    theme: cosmo
fontsize: 14pt
---

```{r global-options, include=FALSE}
knitr::opts_chunk$set(warning=FALSE)
```

```{r setup, include=FALSE, message=F}
knitr::opts_chunk$set(echo = T, collapse=T, warning=F)
```

<style type="text/css">
  body{
  font-size: 18pt;
}

<style type="text/css">
.table {

    width: 40%;
}
</style>

```{r, echo=F}
library(data.table)
library(ggplot2)
library(ggpubr)
library(latex2exp)
```

* Create a new file named `cogs2020_hw_10.R` and save it in
the `cogs2020` folder that you created during Lecture 1.

* If you have not already installed the `data.table`,
`ggplot2`, and `ez` packages, do so now. If you use the
`install.packages` function, do not include it in the script
that you hand in.

* Make the first line of your script `library(data.table)`
the second line `library(ggplot2)`, and the third line
`library(ez)`.

* Make the next line of your script `rm(list=ls())`. This
line of code will erase any variable defined before it. Do
not put this line of code after anything important that you
want to keep (e.g., so that I can mark your work).

* After `rm(list=ls())`, create a variable named `my_name`
and set its value equal to a **character** vector (i.e.,
letters surrounded by `""` or by `''`) containing your name.

* After `rm(list=ls())`, create a variable named
`my_student_id` and set its value equal to a **character**
vector (i.e., letters surrounded by `""` or by `''`)
containing your student id.

* So far, here is what your file should look like if your
name is `John Doe` and and your student ID is `12345678`.

```{r, echo=T, warning=F, message=F}
# load the packages we will need
library(data.table)
library(ggplot2)
library(ez)

# clean session
rm(list=ls())

# basic id info
my_name <- "John Doe"
my_student_id <- "12345678"

# Please include the following line of code as well
set.seed(0)
```

# How to do this problem set
This problem set will not be marked by the same methods used
on previous problem sets. In particular, I will mark these
by hand and I will only be looking to see that you have made
reasonable attempts at each. It is up to you to work with
your peers, with me, and with your tutor to ensure that you
understand everything that you do on this problem set and
everything else covered in any way throughout the unit.
Finally, I may update this problem set leading up to the
final exam with additional problems or revised old problems.
It's all just to help you practice. None of the additions
will count against your marks on this problem set.

# COGS2020 goals
Below, I summarise some major goals of COGS2020 and explain
how they contribute to overall marking in the unit. Only
mastery of skills described in all goals should be
sufficient to earn a mark of high distinction.

* **Goal 1:**
A major goal of COGS2020 is to prepare students to get data
from an experiment, figure out the design of the experiment
(i.e., what factors are within-subject and which factors are
between-subject) by interacting with the data.table and / or
making plots, make relevant diagnostic plots, and perform
basic statistics to quantify patterns seen in the
visualisations of the data. Mastery of this skill implies at
least some mastery of Goal 3 (see below) and so it is
expected should be sufficient to generate a credit or
distinction mark.

* **Goal 2:**
A major goal of COGS2020 is to develop in students a deep
conceptual understanding of Null Hypothesis Significance
Testing (NHST). Students with an understanding at this level
will be well positioned to learn any and every NHST method
that can ever be applied in any context throughout their
research career. Mastery of this skill implies mastery of
Goal 3 (see below) and so it is expected should be
sufficient to generate a credit or distinction mark.
  
* **Goal 3:**
A sub-goal of COGS2020 is to give students the ability to
recognise when and how to use simple statistical tools
(e.g., t-tests and ANOVAs) in the context of simple toy data
examples. Mastery of this skill alone should be sufficient
to generate a passing mark in the unit.

# Goal 1 practice
## Stroop experiment

Below, I have written my own analysis code with comments to
explain my reasoning. The purpose is to give you an example
of the kind of thing we are trying to get good at in this
unit. In reading through my analysis, you will see that I
made lots of mistakes, and that it was only in understanding
the deep principles of NHST that I was able to catch these
mistakes. I swear this wasn't planned... it just happens all
the time. That's partly why I teach this unit with so much
emphasis on concepts. Anyway, you should be sure to
underastand all my code, and then move on to try our hand on
the remaining data sets below.

Consider the experiment here:

* `https://gitlab.pavlovia.org/demos/stroop`
* `https://run.pavlovia.org/demos/stroop/`

You should participate in the experiment to get a feel for
it.

Reasonably cleaned data from this experiment can be found
here: 

* `https://crossley.github.io/cogs2020/data/real_data/data_stroop.csv`

`data_stroop.csv` contains the following columns:

* `subject`: participant indicator
* `resp.keys`: the participant response
* `resp.rt`: the response time of the key press
* `text`: the text displayed
* `letterColor`: the colour of the displayed text
* `group`: the group or participants 

```{r}
library(data.table)
library(ggplot2)
library(ez)

rm(list = ls())

## Load data_stroop.csv into a data.table
d <- fread('https://crossley.github.io/cogs2020/data/real_data/data_stroop.csv')

## Make a violin plot that contains one violin indicating the
## response time on congruent (i.e., `text == letterColor`)
## trials and another violin indicating the response time on
## incongruent (i.e., `text != letterColor`) trials. Make
## sure that each subject contributes only one data point
## (i.e., their mean response time on the desired trial
## type) to each box.
d[, trial_type := 'NA']
d[text == letterColor, trial_type := 'congruent']
d[text != letterColor, trial_type := 'incongruent']

dd <- d[, 
        .(rt_mean = mean(resp.rt)), 
        .(subject, trial_type)]

ggplot(data=dd, aes(x=trial_type, y=rt_mean)) +
  geom_violin() + 
  geom_point()

## Make a point range plot that plots a point at the mean
## value for each trial type and extends error bars in one
## standard error above and below these mean values. In this
## sort of plot, the point will indicate the observed sample
## means, and the error bars will give the viewer an
## indication of how much variability is in the distribution
## of the **test statistic**.
ddd <- dd[, 
         .(rt_mean = mean(rt_mean), 
           rt_err = sd(rt_mean)/sqrt(.N)),
         .(trial_type)]

ggplot(data=ddd, aes(x=trial_type, y=rt_mean)) +
  geom_pointrange(aes(ymin=rt_mean-rt_err, ymax=rt_mean+rt_err))

## Are the mean response times per subject significantly
## greater on congruent trials then they are on
## incongruent trials? Assume equal variance. Ensure an
## expected type I error rate of 0.05.
x <- dd[trial_type == 'incongruent', rt_mean]
y <- dd[trial_type == 'congruent', rt_mean]
t.test(x = x, 
       y = y,
       alternative = c("greater"),
       mu = 0, 
       paired = F, 
       var.equal = T,
       conf.level = 0.95
)

## Do the results of this t-test make sense? Can we be
## confident that we didn't do something careless in our
## coding?

## * t = 2.19 indicates that the difference in the mean
## values between congruent and incongruent trials are just
## a bit more than 2 standard errors apart. We can check
## this, but we need to know what sort of standard error
## this test is / should be using.

## Check for equal sample size
nx <- length(x)
ny <- length(y)

## We do not have equal sample size, and above we are told
## to assume equal variance. We go to the lecture notes to
## find:
sp = sqrt(((nx-1)*var(x) + (ny-1)*var(y)) / (nx + ny - 2)) 
sp_err = sp * sqrt((1/nx) + (1/ny))

## We see that one standard error for this test is about
## 0.09.  

## The difference in means (`mean(x) - mean(y)`) in this
## test is is about .2, which means that we would expect our
## observed t-statistic to be just a bit more than 2. We can 
## check this formally as follows:
t_obs = (mean(x) - mean(y)) / sp_err

## How about the degrees of freedom of this test? Do they
## also check out? From the lecture notes, we expect:
df = nx + ny - 2

## This also lines up with our call to t.test(), but how can
## we be sure we didn't make a mistake wrangling the data?
## How many subjects are in this data set?
d[, length(unique(subject))]

## Each of these subjects should contribute one observation
## to x and one observation to y. Wait... what??? How can we
## have 431 participants and only 422 incongruent
## observations and 414 congruent observations? A good way
## to go about investigating this is to ask how many
## observations in total each subject provides.
dN <- d[, .N, .(subject)][order(N)]
ggplot(data=dN, aes(N)) +
  geom_histogram()

## Ah, we see that quite a few participants didn't complete
## the experiment. It probably makes sense to exclude these
## people from our analysis.
d[, trials_completed := .N, .(subject)]
d <- d[trials_completed == 30]

## From here, we redo all the above analyses
dd <- d[, 
        .(rt_mean = mean(resp.rt)), 
        .(subject, trial_type)]

## Check that each subject gives one observation per trial
## type
dd[, .N, .(subject, trial_type)][, unique(N)]

ggplot(data=dd, aes(x=trial_type, y=rt_mean)) +
  geom_violin() + 
  geom_point()

ddd <- dd[, 
         .(rt_mean = mean(rt_mean), 
           rt_err = sd(rt_mean)/sqrt(.N)),
         .(trial_type)]

ggplot(data=ddd, aes(x=trial_type, y=rt_mean)) +
  geom_pointrange(aes(ymin=rt_mean-rt_err, ymax=rt_mean+rt_err))

x <- dd[trial_type == 'incongruent', rt_mean]
y <- dd[trial_type == 'congruent', rt_mean]
t.test(x = x, 
       y = y,
       alternative = c("greater"),
       mu = 0, 
       paired = F, 
       var.equal = T,
       conf.level = 0.95
)

## Notice below that now that we've got our equal sample
## size sorted out our standard error calculation is
## simplified.
nx <- length(x)
ny <- length(y)
n <- nx
sp_err = sqrt((var(x) + var(y)) / n) 
t_obs = (mean(x) - mean(y)) / sp_err
df = 2*n - 2

## So at the end of the day here, it appears that we do not
## see significantly greater response times on incongruent
## trials as we do on congruent trials. 

## Is this the replication crises in psychology??? Probably
## not. Check out the outliers in the congruent condition
## that will surely be influencing the estimated mean
## difference between these conditions. It would likely be
## quite sensible to remove these outliers from our
## analysis... however, doing so is slippery business and is
## beyond the scope of what I can do for you in this
## introductory unit.

##
##
## How do things turn out for accuracy?
## This is a simple matter of creating and then referencing
## a different column in the top level data.table, so I'll
## fly through this.
##
##
d[, acc := resp.keys == letterColor]
dd <- d[, 
        .(acc_mean = mean(acc)), 
        .(subject, trial_type)]

ggplot(data=dd, aes(x=trial_type, y=acc_mean)) +
  geom_violin() + 
  geom_point()

ddd <- dd[, 
         .(acc_mean = mean(acc_mean), 
           acc_err = sd(acc_mean)/sqrt(.N)),
         .(trial_type)]

ggplot(data=ddd, aes(x=trial_type, y=acc_mean)) +
  geom_pointrange(aes(ymin=acc_mean-acc_err, ymax=acc_mean+acc_err))

x <- dd[trial_type == 'incongruent', acc_mean]
y <- dd[trial_type == 'congruent', acc_mean]
t.test(x = x, 
       y = y,
       alternative = c("less"),
       mu = 0, 
       paired = F, 
       var.equal = T,
       conf.level = 0.95
)

nx <- length(x)
ny <- length(y)
n <- nx
sp_err = sqrt((var(x) + var(y)) / n) 
t_obs = (mean(x) - mean(y)) / sp_err
df = 2*n - 2


##
##
## Ah, crap again. I just realised I forgot to figure out
## whether the factor we are examining (i.e., `trial_type`)
## is within- or between-subject. It's easy to see that it
## is a within-subjects factor. This means that it was not
## appropriate for us to apply an independent samples
## t-test! We should have done a paired samples t-test.
ddesigntype <- dd[, unique(subject), .(trial_type)]
ggplot(ddesigntype, aes(x=trial_type, y=V1)) +
  geom_point()

##  Paired samples t-test for both accuracy and rt
dd <- d[, 
        .(rt_mean = mean(resp.rt), 
          acc_mean = mean(acc)), 
        .(subject, trial_type)]

diff_scores = dd[, .(diff_scores_rt = diff(rt_mean),
                     diff_scores_acc = diff(acc_mean)), 
                 .(subject)]


x <- diff_scores[, diff_scores_rt]
t.test(x = x, 
       y = NULL,
       alternative = c("less"),
       mu = 0, 
       paired = F, 
       var.equal = T,
       conf.level = 0.95
)

n <- length(x)
sp_err = sqrt((var(x)) / n) 
t_obs = (mean(x)) / sp_err
df = n - 1

x <- diff_scores[, diff_scores_acc]
t.test(x = x, 
       y = NULL,
       alternative = c("greater"),
       mu = 0, 
       paired = F, 
       var.equal = T,
       conf.level = 0.95
)

n <- length(x)
sp_err = sqrt((var(x)) / n) 
t_obs = (mean(x)) / sp_err
df = n - 1

## Takeaway: If we do things correctly, then we aren't left
## wondering about the replication crises or how to deal
## with outliers. That is convenient, I suppose.


##
##
## Lets move on to another question. Does `letterColor`
## itself have an effect on response time? E.g., bull
## fighters use red flags to antagonise bulls... perhaps
## that will make people faster? Perhaps other colours have
## a similar or different effect?

## How many colours are there?
d[, unique(letterColor)]

## Which colours belong to which group?
d[, unique(letterColor), .(group)]

## Which factors are within and which are between?
ddesigntype <- d[, unique(subject), .(letterColor, group)]
ggplot(data=ddesigntype, aes(x=letterColor, y=V1, colour=group)) +
  geom_point()

## We can see that letterColor is within-subject and group
## is between-subject

## There are certainly more than two colours, so an ANOVA is
## the most appropriate of our tools to use. 
dd <- d[, 
        .(rt_mean = mean(resp.rt), 
          acc_mean = mean(acc)), 
        .(subject, letterColor, group)]

ggplot(data=dd, aes(x=letterColor, y=rt_mean, colour=group)) +
  geom_violin()

ddd <- dd[, 
         .(rt_mean = mean(rt_mean), rt_err = sd(rt_mean)/sqrt(.N)),
         .(letterColor, group)]

ggplot(data=ddd, aes(x=letterColor, y=rt_mean, colour=group)) +
  geom_pointrange(aes(ymin=rt_mean-rt_err, ymax=rt_mean+rt_err))

ezANOVA(data=dd,
        dv=rt_mean,
        wid=subject,
        within=letterColor,
        between=group,
        type=3)

## First, the ANOVA results line up with the plot we made
## pretty well (main effect of group and not much else). For
## mixed designs, we haven't learned how to perform
## diagnostic checks (i.e., doing everything by hand) as we
## did above for the t-test, so we will leave it at this.
```

## Flanker experiment

Consider the experiment here:

* `https:/gitlab.pavlovia.org/demos/flanker`
* `https:/run.pavlovia.org/demos/flanker`

You should participate in the experiment to get a feel for
it.

Reasonably cleaned data from this experiment can be found
here: 

* `https://crossley.github.io/cogs2020/data/real_data/data_flanker.csv`

`data_flanker.csv` contains the following columns:

* `subject`: participant indicator
* `stimulus`: the presented stimulus
* `condition`: whether the stimulus is congruent or incongruent
* `key_resp.keys`: the response made by the participant
* `response`: the correct response
* `key_resp.rt`: the response time of the key press
* `group`: the group or participants 

```{r}
library(data.table)
library(ggplot2)
library(ez)

rm(list = ls())

## Load data_flanker.csv into a data.table
d <- fread('https://crossley.github.io/cogs2020/data/real_data/data_flanker.csv')

## For each of the questions listed below, make a diagnostic
## plot and perform an appropriate NHST. Perform the most
## robust sanity checks you can to be sure that the results
## you obtain from using built-in R functions are not
## corrupted by incorrect data wrangling, or otherwise
## slippery coding mistakes.

## The classic finding in a flanker experiment is that
## accuracy and reaction times are both better on congruent
## (e.g., `stimulus == '<<<<<'`) trials than on incongruent
## trials (e.g., `stimulus != '<<><<'`). Test this
## hypothesis using an appropriate t-test.

## Does the `group` a participant belongs to make a
## difference in overall accuracy or reaction time?

## Is there any difference in accuracy or reaction time
## between any combination of `group` and `condition`
## (congruent vs incongruent)?

## ## Is there any difference in accuracy or reaction time
## within the congruent stimuli? Within the inconruent
## stimuli?
```

## Visual search experiment
Consider the experiment here:

* `https:/gitlab.pavlovia.org/demos/visual-search`
* `https:/run.pavlovia.org/demos/visual-search`

You should participate in the experiment to get a feel for
it.

Reasonably cleaned data from this experiment can be found
here: 

* `https://crossley.github.io/cogs2020/data/real_data/data_visual_search.csv`

`data_visual_search.csv` contains the following columns:

* `subject`: participant indicator
* `setSize`: number of stimuli on the screen
* `targetCol`: colour of the target image
* `distractorCol`: colour of the distractor images
* `mouse.time`: response time

```{r}
library(data.table)
library(ggplot2)
library(ez)

rm(list = ls())

## Load data_fla.csv into a data.table
d <- fread('https://crossley.github.io/cogs2020/data/real_data/data_visual_search.csv')

## For each of the questions listed below, make a diagnostic
## plot and perform an appropriate NHST. Perform the most
## robust sanity checks you can to be sure that the results
## you obtain from using built-in R functions are not
## corrupted by incorrect data wrangling, or otherwise
## slippery coding mistakes.

## Is the search time longer when the target is the same
## colour as the distractor images?

## Is the the search time longer when set size is bigger?

## Does the target colour have a bigger effect on search
## time at larger set sizes?
```

# Goal 2 practice

## 1.
```{r, echo=F}
mux <- 10
sigx <- 3
n <- 10

muxbar <- mux
sigxbar <- sigx / sqrt(n)

x <- seq(mux-4*sigx, mux+4*sigx, 0.01)
fx <- dnorm(x, mean=mux, sd=sigx)
dx <- data.table(x=x, fx=fx)

xobs <- rnorm(n, mux, sigx)
y <- rep(0, n)
dobs <- data.table(xobs, y)

xbar <- seq(muxbar-15*sigxbar, muxbar+15*sigxbar, 0.01)
fxbar <- dnorm(xbar, mean=muxbar, sd=sigxbar)
dxbar <- data.table(x=xbar, fx=fxbar)

ggplot() +
  geom_line(data=dx, aes(x, fx), colour='red') +
  geom_line(data=dxbar, aes(x, fx), colour='blue') +
  geom_point(data=dobs, aes(x=xobs, y=y)) +
  geom_vline(aes(xintercept=mean(xobs)))
```

* Which distribution generated the observed raw data
illustrated by the black dots?

* Which distribution generated the observed test statistic
(i.e., the sample mean) illustrated by the black vertical
line.

* What type of test does this figure illustrate?

  * `Normal test`
  * `t-test`
  * `Binomial test`
  * `ANOVA`
  * `None of the above`
  * `All of the above`

* What is the null hypothesis of this test?

* Define a specific alternative hypothesis compute the
minimum sample size required required to generate a power of
at least 0.8 and a type I error rate of 0.05. The population
standard deviation of the random variable that generated the
raw data is $\sigma_X = 3$.

## 2.
```{r, echo=F}
mux <- 8
muy <- 10
muz <- 12

sig <- 3
n <- 10

x <- seq(mux-4*sig, muz+4*sig, 0.01)
fx <- dnorm(x, mean=mux, sd=sig)
fy <- dnorm(x, mean=muy, sd=sig)
fz <- dnorm(x, mean=muz, sd=sig)
dxyz <- data.table(x=x, fx=fx, fy=fy, fz=fz)

xobs <- rnorm(n, mux, sig)
yobs <- rnorm(n, muy, sig)
zobs <- rnorm(n, muz, sig)

dobs <- data.table(xobs, yobs, zobs, vp=0)

ggplot() +
  geom_line(data=dxyz, aes(x, fx), colour='red') +
  geom_line(data=dxyz, aes(x, fy), colour='blue') +
  geom_line(data=dxyz, aes(x, fz), colour='green') +
  geom_point(data=dobs, aes(x=xobs, y=vp), color='red') +
  geom_point(data=dobs, aes(x=yobs, y=vp), color='blue') +
  geom_point(data=dobs, aes(x=zobs, y=vp), color='green')
```

* The figure shows a plausible illustration of the
alternative hypothesis for what NHST?

  * `Normal test`
  * `t-test`
  * `Binomial test`
  * `1-way ANOVA`
  * `None of the above`
  * `All of the above`
  
* Draw the sampling distribution of the test statistic given
that there are 10 observations from each illustrated raw
data distribution. Note that -- while you are quite welcome
to use `ggplot` to do this -- it is also okay to simply draw
by hand on a piece of paper. We won't be looking at this
point to mark you. It will be, however, an essential tool
for you to know how to use on the exam.

## 3.
```{r, echo=F}
mux <- 10
muy <- 10
muz <- 10

sigx <- 3
sigy <- 6
sigz <- 9

n <- 10

x <- seq(mux-4*sigz, muz+4*sigz, 0.01)
fx <- dnorm(x, mean=mux, sd=sigx)
fy <- dnorm(x, mean=muy, sd=sigy)
fz <- dnorm(x, mean=muz, sd=sigz)
dxyz <- data.table(x=x, fx=fx, fy=fy, fz=fz)

xobs <- rnorm(n, mux, sigx)
yobs <- rnorm(n, muy, sigy)
zobs <- rnorm(n, muz, sigz)

dobs <- data.table(xobs, yobs, zobs, vp=0)

ggplot() +
  geom_line(data=dxyz, aes(x, fx), colour='red') +
  geom_line(data=dxyz, aes(x, fy), colour='blue') +
  geom_line(data=dxyz, aes(x, fz), colour='green') +
  geom_point(data=dobs, aes(x=xobs, y=vp), color='red') +
  geom_point(data=dobs, aes(x=yobs, y=vp), color='blue') +
  geom_point(data=dobs, aes(x=zobs, y=vp), color='green')
```

* Suppose that raw data is generated from the above
distributions. Is this raw data consistent with the
assumptions made in the null hypothesis of a 1-way ANOVA? If
not, why?

* Suppose we were only interested in pairwise comparisons
between the red, blue, and green random variables. Is the
raw data consistent with the assumptions made in the null
hypothesis of any t-test?

## 4.

* Consider a scenario where researchers are testing for
significant differences between 2 treatments and 2 doses of
each treatment in a fully between-subjects design. Draw the
distributions for the raw data of a possible alternative
hypothesis that shows a significant interaction but no main
effects. Note that -- while you are quite welcome to use
`ggplot` to do this -- it is also okay to simply draw by
hand on a piece of paper. We won't be looking at this point
to mark you. It will be, however, an essential tool for you
to know how to use on the exam.

# Goal 3 practice

```{r, echo=F}
gen_exp <- function(muA1, muA2, muB1, muB2, muC1, muC2, sig, n) {

  ## generate obervations
  y_A1 <- rnorm(n, muA1, sig)
  y_A2 <- rnorm(n, muA2, sig)
  y_B1 <- rnorm(n, muB1, sig)
  y_B2 <- rnorm(n, muB2, sig)
  y_C1 <- rnorm(n, muC1, sig) # new level but same mu
  y_C2 <- rnorm(n, muC2, sig) # new level but same mu

  ## store observations plus relevant indicators in data.table
  d <- data.table(y=c(y_A1, y_A2, y_B1, y_B2, y_C1, y_C2),
                  treatment=rep(c('A', 'B', 'C'), each=2*n),
                  dose=rep(c(1, 2), 3, each=n))

  d[, treatment := factor(treatment)]
  d[, dose := factor(dose)]

  ## main effect of treatment (A vs B)
  dd <- d[, .(mean(y), sd(y)/sqrt(length(unique(dose)))), .(treatment)]
  g1 <- ggplot(dd, aes(treatment, V1)) +
    geom_pointrange(aes(ymin=V1-V2, ymax=V1+V2)) +
    theme_classic() +
    theme(aspect.ratio=1) +
    ylab('Observed mean effect') +
    ggtitle('Main effect')

  ## main effect of dose (1 vs 2)
  dd <- d[, .(mean(y), sd(y)/sqrt(length(unique(treatment)))), .(dose)]
  g2 <- ggplot(dd, aes(dose, V1)) +
    geom_pointrange(aes(ymin=V1-V2, ymax=V1+V2)) +
    theme_classic() +
    theme(aspect.ratio=1) +
    ylab('Observed mean effect') +
    ggtitle('Main effect')

  ## interaction between treatment and dose
  dd <- d[, .(mean(y), sd(y)/sqrt(length(unique(treatment))*length(unique(dose)))), .(treatment, dose)]
  g3 <- ggplot(dd, aes(dose, V1, colour=treatment)) +
    geom_pointrange(aes(ymin=V1-V2, ymax=V1+V2)) +
    geom_line(aes(as.integer(dose), V1, colour=treatment)) +
    theme_classic() +
    theme(aspect.ratio=1) +
    ylab('Observed mean effect') +
    ggtitle('Interaction')

  return(list(g1, g2, g3, unique(d)))
}
```

## 1.
```{r, echo=F}
set.seed(2)
n <- 4
# muA1, muA2, muB1, muB2, muC1, muC2, sig, n
res <- gen_exp(10, 30, 40, 20, 40, 20, 5, n)
g1 <- res[[1]]
g2 <- res[[2]]
g3 <- res[[3]]
d <- res[[4]]
d[, subject := 1:.N]
d <- d[treatment %in% c('A', 'B'), .(y, treatment, subject)]
```

```{r}
d <- fread(
 'y treatment subject
  5.515427          A       1
  10.924246         A       2
  17.939227         A       3
  4.348122          A       4
  29.598741         A       5
  30.662101         A       6
  33.539774         A       7
  28.801510         A       8
  49.922370         B       9
  39.306065         B      10
  42.088254         B      11
  44.908764         B      12
  18.036523         B      13
  14.801655         B      14
  28.911145         B      15
  8.444655          B      16'
)
```

* Use an appropriate NHST to test for significant
differences between treatment A and treatment B.

* Use another appropriate NHST to test for significant
differences between treatment A and treatment B.

* Use an appropriate NHST to test if treatment A is
significantly greater than treatment B.

## 2.
```{r, echo=F}
set.seed(4)
n <- 4
# muA1, muA2, muB1, muB2, muC1, muC2, sig, n
res <- gen_exp(10, 30, 40, 20, 40, 20, 5, n)
g1 <- res[[1]]
g2 <- res[[2]]
g3 <- res[[3]]
d <- res[[4]]
d[, subject := rep(1:(2*n), 3)]
d <- d[treatment %in% c('A', 'B'), .(y, treatment, subject)]
```

```{r}
d <- fread(
 'y treatment subject
  11.083774         A       1
  7.287537          A       2
  14.455723         A       3
  12.979903         A       4
  38.178090         A       5
  33.446377         A       6
  23.593767         A       7
  28.934277         A       8
  49.482699         B       1
  48.884316         B       2
  42.833022         B       3
  40.078597         B       4
  21.915287         B       5
  19.774314         B       6
  20.171760         B       7
  20.845134         B       8'  
)
```

* Use an appropriate NHST to test for significant
differences between treatment A and treatment B.

* Use another appropriate NHST to test for significant
differences between treatment A and treatment B.

* Use an appropriate NHST to test if treatment A is
significantly greater than treatment B.